# üìö Manuel d'architecture et d'ing√©nierie HPC

**Volume 4 : Ordonnancement, gestion des ressources et Slurm (Deep Dive)**

> **Niveau** : DevOps Senior / Architecte HPC ‚Äî **Public** : Master, Doctorat, ing√©nieurs syst√®me

---

## Vue d'ensemble du volume

L'**ordonnanceur** (scheduler) est le **cerveau** du cluster : il arbitre l'acc√®s aux ressources entre les chercheurs, garantit le retour sur investissement du mat√©riel et √©vite le chaos. Ce volume couvre la **th√©orie** de l'ordonnancement (FIFO, Backfill, Fairshare), l'**architecture et le d√©ploiement** de [Slurm](Guide-SLURM-Complet.md) (slurmctld, slurmd, slurmdbd, HA, MUNGE), la **configuration avanc√©e** (cgroups, GRES GPU, topology-aware), puis l'**exploitation et le troubleshooting**. Les [Labs 4 & 5](#-lab-4--5--d√©ploiement-slurm-fairshare-et-cgroups) et l'[examen de fin de volume](#-examen-de-fin-de-volume-4) permettent de valider les acquis.

**Pr√©requis :**
- Algorithmique de base, th√©orie des files d'attente (Ch. 12)
- Administration Linux (systemd), TCP/IP (Ch. 13)
- Noyau Linux (cgroups, namespaces) (Ch. 14)
- Ligne de commande Linux, SQL basique (Ch. 15)

---

## Chapitre 12 : Th√©orie de l'ordonnancement HPC et algorithmique

### Objectifs d'apprentissage

- Ma√Ætriser les algorithmes de base : **FIFO**, **Backfill** et **Fairshare**
- Comprendre le compromis **throughput** (taux d'occupation) vs **latency** (temps d'attente)
- Mod√©liser math√©matiquement la **priorit√©** d'un job

---

### 12.1 Au-del√† du FIFO : le Backfill Scheduling

Un ordonnanceur **pure FIFO** (First-In, First-Out) est inefficace en HPC : si le **Job A** (tr√®s gros) est en t√™te et attend que des n≈ìuds se lib√®rent, il **bloque** tous les petits jobs derri√®re lui et laisse le cluster √† moiti√© vide.

L'algorithme de **Backfill** r√©sout ce probl√®me :

1. Il calcule **√† quel moment** le Job A pourra d√©marrer.
2. Il parcourt la file et **lance les petits jobs** (B, C) sur les n≈ìuds inactifs.
3. **Condition stricte** : ces petits jobs doivent se **terminer avant** l'heure de d√©marrage pr√©vue du Job A.

Cela exige que les utilisateurs d√©clarent un **temps d'ex√©cution maximum** (le **walltime**).

---

### 12.2 La politique de Fairshare (partage √©quitable)

En environnement **multi-tenant**, le **Fairshare** garantit qu'un utilisateur ou un laboratoire obtient la part de ressources (CPU/GPU) pour laquelle il a **pay√©**, sur une p√©riode donn√©e.

- Si un utilisateur **consomme plus** que sa cible ‚Üí sa **priorit√© diminue**.
- S'il **consomme moins** ‚Üí sa priorit√© **augmente**.
- La m√©moire de la consommation **s'estompe** avec le temps (facteur de **demi-vie**, half-life decay).

**Priorit√© finale d'un job dans Slurm** (√©quation composite) :

```
Priority = (W_FS √ó FairShare) + (W_Age √ó Age) + (W_QOS √ó QOS) + (W_Size √ó JobSize)
```

*(W = poids configur√© par l'administrateur pour chaque facteur.)*

---

### Pi√®ge : ¬´ Le walltime parano√Øaque ¬ª

Les utilisateurs demandent **48 h** de walltime pour un job qui dure **2 h**, par peur d'√™tre coup√©s. **Cons√©quence** : le scheduler ne peut pas les utiliser pour le backfill ‚Üí le cluster se vide, l'efficacit√© chute. Il faut **√©duquer** (ou forcer via des limites) les utilisateurs √† profiler leur temps d'ex√©cution.

---

### Check-list production (Chapitre 12)

- [ ] D√©finir un param√®tre **DefaultTime** raisonnable sur chaque partition
- [ ] Activer le plugin **sched/backfill** et ajuster **bf_window** (profondeur de pr√©diction)

---

## Chapitre 13 : Slurm ‚Äî Architecture et d√©ploiement

### Objectifs d'apprentissage

- Cartographier les **d√©mons Slurm** et leurs interactions
- Mettre en place la **haute disponibilit√© (HA)** du contr√¥leur
- Int√©grer **MUNGE** pour l'authentification intra-cluster

---

### 13.1 L'√©cosyst√®me Slurm

Slurm est le **standard de facto** en HPC (plus de 60 % du Top500). Architecture d√©centralis√©e :

| Composant | R√¥le |
|-----------|------|
| **slurmctld** (Controller) | Cerveau. Tourne sur le n≈ìud de management. Maintient l'√©tat du cluster, g√®re les files d'attente, alloue les ressources. |
| **slurmd** (Daemon) | Travailleur. Sur **chaque** n≈ìud de calcul. Surveille les ressources, lance les jobs, nettoie apr√®s leur passage. |
| **slurmdbd** (Database Daemon) | Archiviste. Se connecte √† MariaDB/MySQL pour l'**historique (Accounting)**, la hi√©rarchie des comptes et le **Fairshare**. |

**Sch√©ma : Architecture haute disponibilit√©**

```
 +----------------+       +----------------+
 | Management 1   |       | Management 2   |
 | (Primary)      |       | (Backup)       |
 | - slurmctld    | <---> | - slurmctld    |
 | - slurmdbd     |       | - slurmdbd     |
 +-------+--------+       +--------+-------+
         |                         |
         +------------+------------+
                      | Shared State (StateSaveLocation sur NFS/Lustre)
                      v
 +-----------------------------------------+
 | Compute Nodes (slurmd)                  |
 | Node01, Node02, ..., Node1000           |
 +-----------------------------------------+
```

---

### 13.2 Authentification MUNGE

Slurm n'utilise **pas SSH** pour la communication entre d√©mons. Il utilise **MUNGE** (MUNGE Uid 'N' Gid Emporium) : le payload (UID/GID de l'utilisateur) est **chiffr√©** avec une **cl√© sym√©trique partag√©e** (`/etc/munge/munge.key`). Tous les n≈ìuds doivent poss√©der **exactement la m√™me cl√©** et √™tre **synchronis√©s** (NTP).

---

## Chapitre 14 : Configuration avanc√©e (Cgroups, GPU et topologie)

### Objectifs d'apprentissage

- **Isoler** les jobs avec les **cgroups v2** (√©viter les noisy neighbors)
- Configurer les **GRES** (Generic Resources) pour le placement **GPU**
- Impl√©menter le **topology-aware scheduling**

---

### 14.1 L'isolation par les cgroups

Sans isolation, le Job A et le Job B sur le **m√™me n≈ìud** peuvent se ¬´ vampiriser ¬ª (OOM Killer global). Avec le plugin **task/cgroup**, Slurm enferme chaque job, chaque step et chaque t√¢che dans des **Control Groups** du noyau Linux.

**Snippet production : cgroup.conf (Cgroups v2)**

```ini
CgroupAutomount=yes
ConstrainCores=yes       # Emp√™che un job d'utiliser les c≈ìurs d'un autre
ConstrainRAMSpace=yes    # Tue le job s'il d√©passe sa RAM (prot√®ge le n≈ìud)
ConstrainDevices=yes     # Cache les GPUs non allou√©s (vital pour CUDA)
AllowedRAMSpace=98       # Laisse 2% de RAM pour l'OS (slurmd, sshd)
```

---

### 14.2 GRES (Generic Resources) et GPUs

Slurm ne g√®re nativement que CPU et RAM. Pour les **GPU** (ou des licences), on utilise les **GRES**.

**Snippet production : gres.conf** (n≈ìud avec 4 GPUs)

```ini
# D√©claration des p√©riph√©riques et affinit√© NUMA
Name=gpu Type=a100 File=/dev/nvidia0 Cores=0-15
Name=gpu Type=a100 File=/dev/nvidia1 Cores=16-31
Name=gpu Type=a100 File=/dev/nvidia2 Cores=32-47
Name=gpu Type=a100 File=/dev/nvidia3 Cores=48-63
```

On lie chaque GPU aux **c≈ìurs CPU** sur le m√™me bus PCIe (affinit√© **NUMA**) pour maximiser la bande passante et r√©duire la latence.

---

### 14.3 Partitions vs QOS

| Concept | R√¥le |
|--------|------|
| **Partition** | Limite **mat√©rielle ou logique** (ex. `partition=gpu`, `partition=high_mem`). File d'attente classique. |
| **QOS** (Quality of Service) | Limite **comportementale et priorit√©** (ex. `qos=premium` pour haute priorit√©, `qos=scavenger` pour jobs pr√©emptibles sur ressources oisives). |

---

## Chapitre 15 : Exploitation et troubleshooting Slurm

### Objectifs d'apprentissage

- Diagnostiquer les pannes de n≈ìuds (**drain**, **down**)
- R√©aliser une **mont√©e de version** sans interruption de service
- Lire et interpr√©ter l'**Accounting**

---

### 15.1 Les √©tats des n≈ìuds

Surveillance via **sinfo** :

| √âtat | Signification |
|------|----------------|
| **alloc** | 100 % allou√©. Normal. |
| **idle** | 100 % libre. Normal. |
| **mix** | Partiellement allou√© (ex. 10 c≈ìurs sur 40). |
| **drain** | N≈ìud en vidage. Plus de nouveaux jobs ; jobs en cours peuvent finir. (Maintenance.) |
| **down** | N≈ìud mort ou injoignable par slurmctld. |
| **drng** | En train de se vider **et** injoignable (not responding). |

**Commande : Remettre un n≈ìud en production apr√®s r√©paration**

```bash
scontrol update nodename=compute-045 state=RESUME
```

---

### 15.2 Proc√©dure d'upgrade de Slurm (DANGER)

L'ordre est **absolu** :

1. Mise √† jour de **slurmdbd** (met √† jour le sch√©ma MariaDB).
2. Mise √† jour de **slurmctld** (peut g√©rer des slurmd plus anciens).
3. Mise √† jour des **slurmd** (n≈ìuds de calcul, progressivement).

> **DANGER** : Mettre √† jour **slurmd avant slurmctld**. Le d√©mon du n≈ìud enverra des structures (RPCs) inconnues au contr√¥leur ‚Üí **crash (Segfault)** ou comportement impr√©visible, cluster fig√©.

---

## üß™ Lab 4 & 5 : D√©ploiement Slurm, Fairshare et cgroups

### √ânonc√©

Sur votre mini-cluster (Master, Node01, Node02) :

1. Installez et configurez **MUNGE** sur tous les n≈ìuds.
2. D√©ployez **MariaDB** et **slurmdbd** sur le Master.
3. Configurez **slurm.conf** avec une partition `normal` (Node01, Node02 ; 2 c≈ìurs, 2 GB RAM chacun).
4. Activez l'**accounting** et les **cgroups**.
5. Cr√©ez un compte `science` et un utilisateur `alice` via **sacctmgr**.
6. Lancez un job demandant **plus de RAM** que physiquement disponible ou allou√©.

### Crit√®res de r√©ussite

- **sinfo** affiche les n≈ìuds en √©tat **idle**.
- **sacctmgr show user** affiche `alice` li√©e au compte `science`.
- **Test OOM** : `srun --mem=100M dd if=/dev/zero of=/dev/null bs=200M` doit √™tre **tu√©** (Killed) par le cgroup (OOM-Killer), avec statut **OUT_OF_MEMORY** dans **sacct**.

### Corrig√© (snippets)

```bash
# 1. MUNGE (tous les n≈ìuds)
dnf install munge -y
# Copier /etc/munge/munge.key depuis Master vers Node01/02
chown munge:munge /etc/munge/munge.key ; chmod 400 /etc/munge/munge.key
systemctl enable --now munge

# 2. SlurmDBD (Master)
dnf install slurmdbd mariadb-server -y
systemctl enable --now mariadb
mysql -e "create database slurm_acct; grant all on slurm_acct.* to 'slurm'@'localhost' identified by 'password';"
# √âditer /etc/slurm/slurmdbd.conf, puis d√©marrer le service

# 3. slurm.conf (tous les n≈ìuds)
# NodeName=node[01-02] CPUs=2 RealMemory=2000 State=UNKNOWN
# PartitionName=normal Nodes=node[01-02] Default=YES MaxTime=24:00:00 State=UP

# 5. Cr√©ation utilisateur
sacctmgr add cluster linux
sacctmgr add account science description="Projet Science" Organization="Univ"
sacctmgr add user alice account=science
```

---

## üìù Examen de fin de volume 4

### QCM (1 point chaque)

**1.** Quel m√©canisme permet √† Slurm de lancer des **petits jobs courts** en attendant qu'un tr√®s gros job puisse d√©marrer ?  
- A) Fairshare  
- B) Preemption  
- C) **Backfill**  

**2.** Un job est en √©tat **PD (Pending)** avec la raison **(Resources)**. Que cela signifie-t-il ?  
- A) Le job a plant√© √† cause d'un manque de RAM  
- B) **Le job attend que les ressources (CPU/n≈ìuds) demand√©es se lib√®rent**  
- C) L'utilisateur a d√©pass√© son quota Fairshare et est banni  

**3.** Quel fichier de configuration permet de **lier un GPU** aux c≈ìurs CPU les plus proches (topologie) ?  
- A) **gres.conf**  
- B) cgroup.conf  
- C) slurmdbd.conf  

---

### Question ouverte (Th√©orie et op√©rations)

Votre cluster comporte **1000 n≈ìuds**. La commande **squeue** prend **30 secondes** ; **slurmctld** consomme **100 % d'un c≈ìur** en permanence. Le r√©seau est sain. Vous constatez : `SchedulerParameters=bf_window=10080` (1 semaine de pr√©diction backfill) et `bf_resolution=60` (r√©solution 1 minute).

**Expliquez** pourquoi le contr√¥leur est surcharg√© et **comment** optimiser ces param√®tres de backfill.

**R√©ponse attendue** : **bf_window=10080** oblige le contr√¥leur √† **simuler** le placement de tous les jobs en attente sur **7 jours**, **minute par minute**. Charge algorithmique O(N√óM) insoutenable pour le thread du scheduler. **Optimisation** : r√©duire **bf_window** √† 1440 (24 h) ou 2880 (48 h), et augmenter **bf_resolution** √† 600 (10 min) pour diviser le nombre de calculs temporels par 10.

---

### √âtude de cas : ¬´ Le job fant√¥me et le n≈ìud drain√© ¬ª

Vous observez le n≈ìud **node088** en √©tat **drain**, avec la raison **(Reason) : Kill task failed**.

1. **Que s'est-il pass√©** au niveau de slurmd et des processus Linux du job pr√©c√©dent ?
2. **Quelle fonctionnalit√©** Slurm (cgroup.conf) aurait probablement d√ª emp√™cher cela ?
3. **Quelle s√©quence de commandes** pour nettoyer le n≈ìud et le remettre en service ?

**R√©ponses attendues :**

1. Un job a atteint sa **limite de temps** (walltime) ou a √©t√© **annul√©** (scancel), mais un **processus fils** est devenu **zombie** ou ignore **SIGKILL**. slurmd ne peut pas nettoyer compl√®tement ‚Üí Slurm **draine** le n≈ìud par s√©curit√©.
2. **ConstrainCores=yes** et le syst√®me **cgroups** permettent au noyau de tuer tout le sous-arbre de processus d'un coup.
3. SSH sur le n≈ìud, trouver le processus (`htop` ou `ps aux | grep <user>`), le tuer (`kill -9`), puis **scontrol update nodename=node088 state=RESUME**.

---

## Solutions des QCM

- **Q1** : **C** ‚Äî Backfill.  
- **Q2** : **B** ‚Äî Pending (Resources) = attente de ressources.  
- **Q3** : **A** ‚Äî gres.conf pour lier GPU et c≈ìurs (affinit√©).

---

## üìã Relecture qualit√© du volume 4

- [x] Couverture : Backfill, Fairshare, architecture Slurm (ctld, md, dbd), cgroups, GRES, upgrades, troubleshooting
- [x] Rigueur technique : ordre strict de l'upgrade Slurm (DANGER), liaison NUMA des GPUs dans gres.conf
- [x] Format : Markdown, formule de priorit√©, sch√©mas
- [x] P√©dagogie : Lab complet (MUNGE ‚Üí SlurmDBD), √©tudes de cas SRE (bf_window surcharg√©, job fant√¥me)

---

## Liens utiles

- **[Sommaire complet du Manuel HPC](Manuel-HPC-Sommaire-Complet.md)** : plan des 8 volumes, chapitres, labs
- **[Manuel Architecture HPC ‚Äî Volume 1](Manuel-Architecture-HPC-Volume1.md)** : fondations, provisioning
- **[Manuel Architecture HPC ‚Äî Volume 2](Manuel-Architecture-HPC-Volume2.md)** : r√©seaux, InfiniBand, s√©curit√©
- **[Manuel Architecture HPC ‚Äî Volume 3](Manuel-Architecture-HPC-Volume3.md)** : stockage parall√®le, Lustre
- **[Guide SLURM Complet](Guide-SLURM-Complet.md)** : commandes utilisateur, sbatch, srun, partitions
- **[Glossaire et Acronymes](Glossaire-et-Acronymes.md)** : Slurm, MUNGE, GRES, cgroups, etc.
- **[Home](Home.md)** : page d'accueil du wiki

---

**Volume 4** ‚Äî Ordonnancement, gestion des ressources et Slurm (Deep Dive)  
**Derni√®re mise √† jour** : 2024
