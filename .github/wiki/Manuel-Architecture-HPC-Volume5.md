# üìö Manuel d'architecture et d'ing√©nierie HPC

**Volume 5 : Toolchains, MPI, GPU et conteneurs**

> **Niveau** : DevOps Senior / Architecte HPC ‚Äî **Public** : Master, Doctorat, ing√©nieurs syst√®me

---

## Vue d'ensemble du volume

Apr√®s l'infrastructure mat√©rielle, le stockage et l'ordonnanceur, ce volume couvre la **couche qui interagit directement avec les chercheurs** : environnements logiciels, compilation et ex√©cution massivement parall√®le. On y traite les **toolchains** (Lmod, Spack, Apptainer), le **parall√©lisme MPI** (s√©mantique, binding NUMA, UCX), puis l'**acc√©l√©ration GPU et IA** (NCCL, GPUDirect RDMA, lancement Slurm). Les [Labs 6 & 7](#-lab-6--7--toolchains-et-d√©ploiement-ia) et l'[examen de fin de volume](#-examen-de-fin-de-volume-5) permettent de valider les acquis.

**Pr√©requis :**
- Compilation Linux (GCC, Make, CMake), variables d'environnement (PATH, LD_LIBRARY_PATH) ‚Äî Ch. 16
- Architecture NUMA, C/C++ ou Fortran de base ‚Äî Ch. 17
- Notions PCIe, acc√©l√©ration mat√©rielle ‚Äî Ch. 18

---

## Chapitre 16 : Environnements utilisateurs et toolchains (Spack & Lmod)

### Objectifs d'apprentissage

- D√©ployer et g√©rer un **arbre de modules** hi√©rarchique avec **Lmod**
- Automatiser la compilation de stacks complexes avec **Spack**
- Ex√©cuter des charges de travail via **Apptainer** (ex-Singularity) de fa√ßon s√©curis√©e

---

### 16.1 Le chaos des d√©pendances et Lmod

En HPC, un chercheur peut avoir besoin de **GCC 11** pour le code A et de **GCC 13 + OpenMPI 4** pour le code B. Installer tout globalement dans `/usr/bin` est impossible. Les **Modules d'environnement**, et en particulier **Lmod** (TACC, √©crit en Lua), permettent de **charger/d√©charger** dynamiquement les variables d'environnement.

**Exemple de Modulefile Lmod (Lua) pour OpenMPI :**

```lua
help([[
Ce module charge OpenMPI 4.1.5 compil√© avec GCC 11.2.
]])
whatis("Version: 4.1.5")
whatis("Compiler: gcc/11.2.0")

-- Emp√™che le chargement de deux versions d'OpenMPI simultan√©ment
conflict("openmpi")
-- S'assure que le bon compilateur est charg√©
prereq("gcc/11.2.0")

local base = "/opt/hpc/software/openmpi/4.1.5-gcc11"
prepend_path("PATH", pathJoin(base, "bin"))
prepend_path("LD_LIBRARY_PATH", pathJoin(base, "lib"))
```

---

### 16.2 Spack : le gestionnaire de paquets des supercalculateurs

**Spack** automatise le t√©l√©chargement, la **compilation** (depuis les sources) et la **g√©n√©ration des modules Lmod**. Il g√®re un graphe de d√©pendances combinatoire (ex. HDF5 avec ou sans MPI, GCC ou Intel).

**Snippet : Installation d'un package via Spack**

```bash
# HDF5 1.14.0, GCC 12.2, support MPI (OpenMPI 4.1.5)
spack install hdf5@1.14.0 %gcc@12.2.0 +mpi ^openmpi@4.1.5
```

---

### 16.3 Conteneurs HPC : Apptainer (ex-Singularity)

Docker n√©cessite un d√©mon **root** ‚Üí faille de s√©curit√© en HPC. **Apptainer** r√©sout cela :

| Caract√©ristique | B√©n√©fice |
|-----------------|-----------|
| **Rootless** | L'utilisateur a les **m√™mes UID/GID** √† l'int√©rieur qu'√† l'ext√©rieur. |
| **Int√©gration** | `/home` et le stockage parall√®le (Lustre) sont mont√©s automatiquement. |
| **Format** | Image **SIF** (Singularity Image Format), fichier unique facile √† d√©placer. |

---

### Pi√®ge : ¬´ Le LD_LIBRARY_PATH toxique ¬ª

Mettre `export LD_LIBRARY_PATH=/path/to/lib` dans le **~/.bashrc** casse silencieusement des commandes syst√®me (`ls`, `ssh`) ou les autres modules Lmod. **R√®gle** : l'environnement doit √™tre **vierge** au login ; tout chargement via **modules** uniquement.

---

### Check-list production (Chapitre 16)

- [ ] Hi√©rarchie Lmod stricte : **Core ‚Üí Compilateur ‚Üí MPI**
- [ ] Configurer Apptainer pour **lier (bind)** automatiquement les **drivers GPU** h√¥tes (`--nv`)

---

## Chapitre 17 : Parall√©lisme et MPI (Deep Dive)

### Objectifs d'apprentissage

- Comprendre les protocoles de transfert MPI (**Eager** vs **Rendezvous**)
- Ma√Ætriser le **placement des processus** (rank mapping, binding NUMA)
- Configurer la couche de transport **UCX**

---

### 17.1 S√©mantique MPI : Eager vs Rendezvous

Le temps de communication peut √™tre mod√©lis√© par l'**√©quation de Hockney** :

```
T_comm = Œ± + L/Œ≤
```

*(Œ± = latence r√©seau, L = taille du message, Œ≤ = bande passante.)*

Pour minimiser Œ±, MPI utilise deux protocoles selon la **taille du message** :

| Protocole | Usage | Comportement |
|-----------|--------|----------------|
| **Eager** (petits messages) | Envoi direct, buffer pr√©-allou√© c√¥t√© r√©cepteur | Tr√®s rapide ; risque d'engorgement m√©moire si trop de messages. |
| **Rendezvous** (gros messages) | RTS (Ready to Send) ‚Üí r√©cepteur r√©pond CTS (Clear to Send) ‚Üí transfert (souvent **RDMA** direct) | √âvite la saturation des buffers. |

---

### 17.2 Rank mapping, binding et topologie NUMA

Sur un processeur multi-chiplets (ex. AMD EPYC), si un rang MPI s'ex√©cute sur le **c≈ìur 0** mais alloue sa m√©moire sur la **RAM du socket 1** (c≈ìur 60), la bande passante m√©moire s'effondre.

**Sch√©ma : Importance du binding**

```
MAUVAIS BINDING (migration OS)       BON BINDING (--bind-to core)
T0: Rank 0 sur CPU 0                 T0: Rank 0 bloqu√© sur CPU 0
T1: Rank 0 migre sur CPU 8           T1: Rank 0 reste sur CPU 0
(Cache L3 perdu, latence explose)    (Cache L3 chaud, perfs maximales)
```

**Commande de lancement optimis√©e (OpenMPI via Slurm) :**

```bash
# Slurm alloue les c≈ìurs ; OpenMPI force le binding (--bind-to core)
# et place les rangs s√©quentiels sur le m√™me n≈ìud (--map-by node)
srun --mpi=pmix mpirun --map-by node --bind-to core ./mon_code_fluides
```

---

### 17.3 UCX (Unified Communication X)

OpenMPI et MPICH ne g√®rent plus directement InfiniBand ; ils d√©l√®guent √† **UCX**. UCX choisit dynamiquement le meilleur chemin : **m√©moire partag√©e** (intra-n≈ìud), **RDMA** (inter-n≈ìuds), **GPU-to-GPU**.

---

## Chapitre 18 : Acc√©l√©ration GPU et IA en HPC

### Objectifs d'apprentissage

- Appr√©hender le **mod√®le d'ex√©cution** mat√©riel des GPU
- Comprendre **NCCL** et **GPUDirect RDMA**
- Configurer le **couplage CPU-GPU** dans [Slurm](Guide-SLURM-Complet)

---

### 18.1 Le goulot d'√©tranglement PCIe

Un GPU (ex. NVIDIA H100) est connect√© au CPU via **PCIe** (ex. Gen5 ‚âà 64 GB/s), bien plus lent que la **VRAM** du GPU (HBM3 ‚âà 3 TB/s).

**Anti-pattern** : copier CPU ‚Üí GPU, faire une op√©ration, rapatrier CPU √† **chaque it√©ration**.

---

### 18.2 GPUDirect RDMA et NCCL

Pour l'entra√Ænement IA sur **100 GPU** (25 n≈ìuds), les GPU s'√©changent les **gradients** (AllReduce).

- **Sans GPUDirect** : GPU ‚Üí RAM CPU ‚Üí HCA ‚Üí R√©seau ‚Üí HCA distante ‚Üí RAM CPU ‚Üí GPU distant ‚Üí **catastrophique**.
- **Avec GPUDirect RDMA** : la carte r√©seau (ex. ConnectX-7) **lit directement la VRAM** du GPU via PCIe, **sans r√©veiller le CPU**.

**NCCL** (NVIDIA Collective Communication Library) orchestre les √©changes (anneaux, arbres) pour maximiser la bande passante.

---

### 18.3 Lancement hybride CPU/GPU sous Slurm

Il faut **lier** chaque processus MPI au **bon GPU** (m√™me racine PCIe).

**Snippet : Job IA multi-GPU avec binding strict**

```bash
#!/bin/bash
#SBATCH --job-name=train_llm
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=4      # 1 t√¢che MPI par GPU
#SBATCH --gpus-per-node=4
#SBATCH --gpu-bind=closest       # T√¢che MPI li√©e au GPU le plus proche (topologie)

srun python train.py
```

---

### DANGER en prod : ¬´ Le pilote mismatch ¬ª

Mettre √† jour le **noyau Linux** sans recompiler les **modules kernel NVIDIA** (DKMS) ou le pilote **OFED**. **Sympt√¥me** : les GPU disparaissent ou les jobs NCCL tombent en **segmentation fault**.

---

## üß™ Lab 6 & 7 : Toolchains et d√©ploiement IA

### √ânonc√©

**Lab 6 (Spack)** : Installez Spack. Compilez **osu-micro-benchmarks** (OMB) avec OpenMPI. G√©n√©rez le module Lmod, chargez-le, et ex√©cutez un test **osu_bw** (bande passante point √† point) entre **deux processus sur le m√™me n≈ìud**.

**Lab 7 (Apptainer)** : Cr√©ez un fichier de d√©finition Apptainer (`pytorch.def`) bas√© sur l'image Docker officielle **NVIDIA PyTorch**. Buildez l'image SIF. Soumettez un job Slurm qui ex√©cute `python -c "import torch; print(torch.cuda.is_available())"` **dans le conteneur**.

### Crit√®res de r√©ussite

- **osu_bw** affiche un tableau de bande passante atteignant la limite de la **m√©moire RAM** (intra-n≈ìud).
- Le job Slurm retourne **True** et a utilis√© l'int√©gration GPU native d'Apptainer (`--nv`).

### Corrig√© (grandes lignes)

```bash
# Lab 6 : Spack & OMB
git clone -c feature.manyFiles=true https://github.com/spack/spack.git
source spack/share/spack/setup-env.sh
spack install osu-micro-benchmarks ^openmpi
spack module lmod refresh -y
module load osu-micro-benchmarks
mpirun -np 2 --bind-to core osu_bw

# Lab 7 : Apptainer & PyTorch
cat << EOF > pytorch.def
Bootstrap: docker
From: nvcr.io/nvidia/pytorch:23.10-py3
EOF
apptainer build pytorch.sif pytorch.def
# Ex√©cution via Slurm (GRES GPU configur√©s)
srun --gpus=1 apptainer exec --nv pytorch.sif python -c "import torch; print(torch.cuda.is_available())"
```

---

## üìù Examen de fin de volume 5

### QCM (1 point chaque)

**1.** Pourquoi Lmod est-il structur√© de mani√®re **hi√©rarchique** (ex. Core ‚Üí Compiler ‚Üí MPI) ?  
- A) Pour des raisons esth√©tiques dans `module avail`  
- B) **Pour emp√™cher de charger une biblioth√®que (ex. HDF5 compil√© avec GCC) si un compilateur incompatible (ex. Intel) est d√©j√† charg√©**  
- C) Parce que Spack l'impose par d√©faut  

**2.** Quel est l'avantage principal d'**Apptainer** par rapport √† Docker en HPC ?  
- A) Apptainer est plus rapide pour ex√©cuter du Python  
- B) **Apptainer fonctionne sans d√©mon root ; l'utilisateur ne peut pas √©lever ses privil√®ges sur l'h√¥te**  
- C) Apptainer inclut nativement toutes les licences logicielles  

---

### Question ouverte (Optimisation MPI)

Un utilisateur lance une simulation MPI sur **2 n≈ìuds** (128 c≈ìurs chacun, 256 rangs). Si le cluster est **vide**, le job dure **1 h**. Si le cluster est **tr√®s charg√©** (mais ses 2 n≈ìuds lui sont d√©di√©s √† 100 %), le job dure **1 h 30**. L'application fait de **lourds MPI_Allreduce**.

**Expliquez** le ph√©nom√®ne physique/r√©seau qui ralentit le job et **comment** les concepteurs de r√©seaux HPC tentent de le mitiger (indices : congestion, topologie de la fabric).

**R√©ponse attendue** : Le **r√©seau** (InfiniBand ou Ethernet) est **partag√©**. **Congestion r√©seau** (network contention) : les flux d'autres jobs saturent les liens des switches Spine/Leaf et perturbent la synchronisation des **MPI_Allreduce**. **Mitigations** : routage adaptatif (OpenSM), contr√¥le de congestion (ECN), **topology-aware scheduling** (Slurm place les n≈ìuds sur le m√™me Leaf pour limiter le passage par le Spine).

---

### √âtude de cas : ¬´ Le goulot d'√©tranglement fant√¥me du Deep Learning ¬ª

Une √©quipe entra√Æne un mod√®le sur **4 n≈ìuds √ó 4 GPU A100** (NVLink interne, InfiniBand 200 Gbps entre n≈ìuds). **nvtop** montre une **utilisation GPU plafonnant √† 30 %**. **ib_write_bw** confirme 200 Gbps sur la carte r√©seau.

1. **Quel m√©canisme** de transfert direct est probablement **d√©sactiv√© ou mal configur√©** ?
2. **Quelle variable d'environnement NCCL** demanderiez-vous pour activer un mode **d√©bogage r√©seau** (ex. `NCCL_DEBUG=...`) ?

**R√©ponses attendues :**

1. **GPUDirect RDMA** n'est pas actif (souvent : module noyau **nv_peer_mem** manquant ou incompatibilit√© IOMMU/PCIe). Les transferts NCCL passent par le **CPU** ‚Üí saturation PCIe, GPU en attente (starvation).
2. **`export NCCL_DEBUG=INFO`**. Les logs indiquent si NCCL utilise la couche **SYS** (CPU/RAM) au lieu de **NET/IB** (RDMA direct).

---

## Solutions des QCM

- **Q1** : **B** ‚Äî Hi√©rarchie pour √©viter les conflits de d√©pendances (compilateur/biblioth√®que).
- **Q2** : **B** ‚Äî Rootless, pas de d√©mon root, pas d'√©l√©vation de privil√®ges.

---

## üìã Relecture qualit√© du volume 5

- [x] Couverture : Lmod/Spack, Apptainer vs Docker, MPI (Eager/Rendezvous), binding NUMA, UCX, GPU, NCCL, GPUDirect
- [x] Rigueur technique : √©quation de Hockney, bypass m√©moire GPUDirect RDMA
- [x] Format : Markdown, sch√©mas (binding, protocoles)
- [x] P√©dagogie : Labs Spack + OMB, Apptainer + PyTorch, √©tudes de cas (congestion, NCCL)

---

## Liens utiles

- **[Sommaire complet du Manuel HPC](Manuel-HPC-Sommaire-Complet)** : plan des 8 volumes, chapitres, labs
- **[Manuel Architecture HPC ‚Äî Vol. 1 √† 4](Manuel-Architecture-HPC-Volume1)** : fondations, r√©seaux, stockage, Slurm
- **[Guide SLURM Complet](Guide-SLURM-Complet)** : partitions, GRES, sbatch, srun
- **[Glossaire et Acronymes](Glossaire-et-Acronymes)** : MPI, RDMA, NUMA, NCCL, UCX, etc.
- **[Home](Home)** : page d'accueil du wiki

---

**Volume 5** ‚Äî Toolchains, MPI, GPU et conteneurs  
**Derni√®re mise √† jour** : 2024
