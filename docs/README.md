# Infrastructure HPC Monitoring - Documentation Compl√®te

## Classification: Architecture Technique - Niveau S√©nior

Infrastructure de monitoring compl√®te pour cluster HPC simul√© via Docker, compos√©e de :
- **2 n≈ìuds frontaux** (master/backup)
- **6 n≈ìuds de calcul** (workers)
- **Stack monitoring**: Prometheus + Grafana + Telegraf
- **Environnement**: SUSE Linux Enterprise Server 15 SP7 / openSUSE Leap 15.4

**Contrainte critique**: D√©ploiement air-gapped (hors ligne) - Package autonome exportable via cl√© USB.

---

## üìã Table des Mati√®res

1. [Architecture](#architecture)
2. [Pr√©requis](#pr√©requis)
3. [Installation Rapide](#installation-rapide)
4. [D√©ploiement Offline (Air-Gapped)](#d√©ploiement-offline-air-gapped)
5. [Configuration](#configuration)
6. [Utilisation](#utilisation)
7. [R√©seaux et IPs](#r√©seaux-et-ips)
8. [S√©curit√©](#s√©curit√©)
9. [D√©pannage](#d√©pannage)
10. [Structure du Projet](#structure-du-projet)

---

## üèóÔ∏è Architecture

### Topologie R√©seau

- **VLAN Management**: `172.20.0.0/24` (monitoring)
  - Prometheus: `172.20.0.10`
  - Grafana: `172.20.0.20`
  - Frontaux: `172.20.0.101-102`
  - Slaves: `172.20.0.201-206`

- **VLAN Cluster**: `10.0.0.0/24` (communication inter-n≈ìuds)
  - Frontaux: `10.0.0.101-102`
  - Slaves: `10.0.0.201-206`

### Composants

| Service | Image | Ports | Description |
|---------|-------|-------|-------------|
| Prometheus | prom/prometheus:v2.48.0 | 9090 | Collecte et stockage des m√©triques |
| Grafana | grafana/grafana:10.2.0 | 3000 | Visualisation et dashboards |
| Frontal-01 | Custom (openSUSE) | 2222, 9100, 9273 | N≈ìud frontal principal |
| Frontal-02 | Custom (openSUSE) | 2223, 9101, 9274 | N≈ìud frontal secondaire |
| Slave-01 √† 06 | Custom (openSUSE) | 9102-9107, 9275-9280 | N≈ìuds de calcul |

### Services par N≈ìud

**Frontaux:**
- SSH (port 22)
- Node Exporter (port 9100)
- Telegraf (port 9273)
- SlurmCTLD (optionnel)

**Slaves:**
- SSH (port 22)
- Node Exporter (port 9100)
- Telegraf (port 9273)
- SlurmD (optionnel)

---

## üì¶ Pr√©requis

### Sur Machine de Build (Online)

- **OS**: openSUSE Leap 15.4 ou SUSE SLES 15 SP7
- **Docker**: 20.10+ (API 1.41+)
- **Docker Compose**: 1.29+ ou Docker Compose V2
- **Espace disque**: 15GB minimum (pour images + export)
- **RAM**: 4GB minimum recommand√©
- **Acc√®s Internet**: Pour t√©l√©charger les images de base

### Sur Serveur Cible (Offline)

- **OS**: SUSE SLES 15 SP7 ou openSUSE Leap 15.4
- **Docker**: 20.10+
- **Docker Compose**: 1.29+ ou Docker Compose V2
- **Espace disque**: 10GB minimum
- **RAM**: 4GB minimum recommand√©
- **Cl√© USB**: Pour transfert du package d'export

---

## üöÄ Installation Rapide

### Option 1: Script d'Installation Automatique

```bash
chmod +x INSTALL.sh
./INSTALL.sh
```

### Option 2: Makefile

```bash
make install
```

### Option 3: Commandes Manuelles

```bash
# Build des images
docker-compose build

# D√©marrage
docker-compose up -d

# V√©rification
docker-compose ps
```

### Acc√®s aux Services

- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000
  - Login: `admin`
  - Password: `demo-hpc-2024`
- **SSH Frontal-01**: `ssh root@localhost -p 2222` (password: `hpc-demo-2024`)
- **SSH Frontal-02**: `ssh root@localhost -p 2223` (password: `hpc-demo-2024`)

---

## üíæ D√©ploiement Offline (Air-Gapped)

### √âtape 1: Build et Export sur Machine Online

```bash
# M√©thode 1: Script d√©di√©
./scripts/build-and-export.sh

# M√©thode 2: Makefile
make export

# M√©thode 3: Manuel
docker-compose build
docker save <images> | gzip > images.tar.gz
```

Le script g√©n√®re un r√©pertoire `hpc-export/TIMESTAMP/` contenant:
- `images/`: Archives tar.gz de toutes les images Docker
- `configs/`: Toutes les configurations
- `scripts/`: Scripts d'entrypoint et utilitaires
- `docker-compose.yml`: Fichier d'orchestration
- `import-images.sh`: Script d'import automatique

### √âtape 2: Cr√©ation de l'Archive pour USB

```bash
cd hpc-export
tar -czf hpc-monitoring-$(date +%Y%m%d).tar.gz TIMESTAMP/
# Copier sur cl√© USB
```

### √âtape 3: Installation sur Serveur Offline

```bash
# 1. Extraire l'archive
tar -xzf hpc-monitoring-YYYYMMDD.tar.gz
cd TIMESTAMP/

# 2. Importer les images Docker
chmod +x import-images.sh
./import-images.sh

# 3. V√©rifier les images import√©es
docker images

# 4. D√©marrer l'infrastructure
docker-compose up -d

# 5. V√©rifier le statut
docker-compose ps
```

---

## ‚öôÔ∏è Configuration

### Prometheus

**Fichier**: `configs/prometheus/prometheus.yml`

- **Retention**: 15 jours
- **Scrape interval**: 15 secondes
- **Targets**: 16 targets (8 Node Exporters + 8 Telegraf)

**Modification**:
```bash
vim configs/prometheus/prometheus.yml
docker-compose restart prometheus
```

### Grafana

**Datasource**: Auto-provisionn√© via `configs/grafana/provisioning/datasources/prometheus.yml`

**Dashboards**: Auto-charg√©s depuis `grafana-dashboards/`

**Dashboards inclus**:
- HPC Cluster Overview (statuts n≈ìuds, CPU, Memory, Disk, Network)
- CPU & Memory by Node
- Network I/O

**Ajout de dashboard**:
1. Cr√©er un dashboard dans Grafana UI
2. Exporter en JSON
3. Placer dans `grafana-dashboards/`
4. Red√©marrer Grafana

### Telegraf

**Frontaux**: `configs/telegraf/telegraf-frontal.conf`
**Slaves**: `configs/telegraf/telegraf-slave.conf`

**M√©triques collect√©es**:
- CPU, Memory, Disk, Disk I/O
- Network, Processes, Kernel
- System Load
- Slurm (optionnel, d√©commenter si install√©)

**Modification**:
```bash
vim configs/telegraf/telegraf-frontal.conf
docker-compose restart frontal-01 frontal-02
```

### Alertes Prometheus

**Fichier**: `configs/prometheus/alerts.yml`

**Alertes configur√©es**:
- High/Critical CPU Usage (80%/95%)
- High/Critical Memory Usage (85%/95%)
- High/Critical Disk Usage (80%/90%)
- High Network Traffic
- Node Exporter/Telegraf Down

---

## üéØ Utilisation

### Commandes Makefile

```bash
make help          # Aide compl√®te
make build         # Build des images
make start         # D√©marrage
make stop          # Arr√™t
make restart       # Red√©marrage
make logs          # Logs de tous les services
make status        # Statut des services
make health        # V√©rification de sant√©
make clean         # Nettoyage complet (ATTENTION: supprime les donn√©es)
make export        # Export pour d√©ploiement offline
```

### Commandes Docker Compose

```bash
# D√©marrage
docker-compose up -d

# Arr√™t
docker-compose down

# Logs
docker-compose logs -f [service-name]

# Statut
docker-compose ps

# Rebuild d'un service
docker-compose build [service-name]
docker-compose up -d [service-name]

# Acc√®s shell dans un conteneur
docker-compose exec [service-name] /bin/bash
```

### V√©rification des M√©triques

**Prometheus Targets**:
```bash
curl http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .labels.job, health: .health}'
```

**M√©triques Node Exporter**:
```bash
curl http://localhost:9100/metrics
```

**M√©triques Telegraf**:
```bash
curl http://localhost:9273/metrics
```

### Dashboards Grafana

1. Acc√©der √† http://localhost:3000
2. Login: `admin` / `demo-hpc-2024`
3. Naviguer vers **Dashboards** ‚Üí **HPC Monitoring**
4. Dashboards disponibles:
   - **HPC Cluster Overview**: Vue d'ensemble du cluster
   - **CPU & Memory by Node**: D√©tails CPU/Memory par n≈ìud
   - **Network I/O**: Statistiques r√©seau

---

## üåê R√©seaux et IPs

### R√©seau Management (172.20.0.0/24)

| Service | IP | Ports |
|---------|----|----|
| Prometheus | 172.20.0.10 | 9090 |
| Grafana | 172.20.0.20 | 3000 |
| Frontal-01 | 172.20.0.101 | 2222, 9100, 9273 |
| Frontal-02 | 172.20.0.102 | 2223, 9101, 9274 |
| Slave-01 | 172.20.0.201 | 9102, 9275 |
| Slave-02 | 172.20.0.202 | 9103, 9276 |
| Slave-03 | 172.20.0.203 | 9104, 9277 |
| Slave-04 | 172.20.0.204 | 9105, 9278 |
| Slave-05 | 172.20.0.205 | 9106, 9279 |
| Slave-06 | 172.20.0.206 | 9107, 9280 |

### R√©seau Cluster (10.0.0.0/24)

| Service | IP |
|---------|----|
| Frontal-01 | 10.0.0.101 |
| Frontal-02 | 10.0.0.102 |
| Slave-01 | 10.0.0.201 |
| Slave-02 | 10.0.0.202 |
| Slave-03 | 10.0.0.203 |
| Slave-04 | 10.0.0.204 |
| Slave-05 | 10.0.0.205 |
| Slave-06 | 10.0.0.206 |

---

## üîí S√©curit√©

### Hardening Appliqu√©

**Sysctl**:
- `kernel.randomize_va_space = 2` (ASLR activ√©)
- `net.ipv4.tcp_syncookies = 1` (Protection SYN flood)

**SSH**:
- Protocol 2 uniquement
- X11Forwarding d√©sactiv√©
- PermitRootLogin yes (pour d√©mo uniquement)

**Conteneurs**:
- Mode privil√©gi√© uniquement si n√©cessaire (systemd)
- Volumes de config en lecture seule (`:ro`)
- Healthchecks sur tous les services critiques

### Recommandations Production

‚ö†Ô∏è **IMPORTANT**: Cette configuration est pour d√©monstration. Pour production:

1. **Changer les mots de passe par d√©faut**:
   - Grafana: `demo-hpc-2024` ‚Üí mot de passe fort
   - SSH root: `hpc-demo-2024` ‚Üí d√©sactiver root, utiliser cl√©s SSH

2. **S√©curiser les r√©seaux**:
   - Isoler les r√©seaux Docker du r√©seau h√¥te
   - Utiliser des firewall rules

3. **Mettre √† jour r√©guli√®rement**:
   - Images Docker (Prometheus, Grafana)
   - Packages syst√®me dans les conteneurs

4. **Audit et logging**:
   - Activer les logs d'audit syst√®me
   - Centraliser les logs (ELK, Loki)

---

## üîß D√©pannage

### Services ne d√©marrent pas

```bash
# V√©rifier les logs
docker-compose logs [service-name]

# V√©rifier les ports
netstat -tulpn | grep -E "(9090|3000|2222)"

# V√©rifier les r√©seaux Docker
docker network ls
docker network inspect hpc-docker_management
```

### Prometheus ne scrape pas les targets

```bash
# V√©rifier la configuration
docker-compose exec prometheus cat /etc/prometheus/prometheus.yml

# V√©rifier la connectivit√© r√©seau
docker-compose exec prometheus ping 172.20.0.101

# V√©rifier les targets
curl http://localhost:9090/api/v1/targets
```

### Grafana ne se connecte pas √† Prometheus

1. V√©rifier que Prometheus est UP: `curl http://localhost:9090/-/healthy`
2. V√©rifier la config datasource: `configs/grafana/provisioning/datasources/prometheus.yml`
3. Red√©marrer Grafana: `docker-compose restart grafana`

### Node Exporter ou Telegraf non accessibles

```bash
# V√©rifier les processus dans le conteneur
docker-compose exec frontal-01 ps aux | grep -E "(node_exporter|telegraf)"

# V√©rifier les ports
docker-compose exec frontal-01 netstat -tulpn | grep -E "(9100|9273)"

# V√©rifier les logs
docker-compose logs frontal-01
```

### Probl√®mes de build

```bash
# Nettoyer le cache Docker
docker system prune -a

# Rebuild sans cache
docker-compose build --no-cache

# V√©rifier l'espace disque
df -h
```

### Probl√®mes d'export/import

```bash
# V√©rifier la taille des images
docker images

# V√©rifier l'espace disque disponible
df -h

# Import manuel si le script √©choue
gunzip -c images/image-name.tar.gz | docker load
```

---

## üìÅ Structure du Projet

```
hpc-docker/
‚îú‚îÄ‚îÄ docker-compose.yml          # Orchestration compl√®te
‚îú‚îÄ‚îÄ Dockerfile.frontal          # Image pour n≈ìuds frontaux
‚îú‚îÄ‚îÄ Dockerfile.slave           # Image pour n≈ìuds de calcul
‚îú‚îÄ‚îÄ Makefile                    # Commandes automatis√©es
‚îú‚îÄ‚îÄ INSTALL.sh                  # Script d'installation one-click
‚îú‚îÄ‚îÄ README.md                   # Cette documentation
‚îÇ
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml      # Configuration scraping
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ alerts.yml          # R√®gles d'alerte
‚îÇ   ‚îú‚îÄ‚îÄ telegraf/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ telegraf-frontal.conf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ telegraf-slave.conf
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ       ‚îî‚îÄ‚îÄ provisioning/
‚îÇ           ‚îú‚îÄ‚îÄ datasources/
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml
‚îÇ           ‚îî‚îÄ‚îÄ dashboards/
‚îÇ               ‚îî‚îÄ‚îÄ default.yml
‚îÇ
‚îú‚îÄ‚îÄ grafana-dashboards/
‚îÇ   ‚îú‚îÄ‚îÄ hpc-cluster-overview.json
‚îÇ   ‚îú‚îÄ‚îÄ cpu-memory-by-node.json
‚îÇ   ‚îî‚îÄ‚îÄ network-io.json
‚îÇ
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ entrypoint-frontal.sh   # Script d'initialisation frontaux
    ‚îú‚îÄ‚îÄ entrypoint-slave.sh     # Script d'initialisation slaves
    ‚îî‚îÄ‚îÄ build-and-export.sh     # Script d'export pour offline
```

---

## üìä M√©triques Disponibles

### Node Exporter (port 9100)

- `node_cpu_seconds_total`: Utilisation CPU par mode
- `node_memory_*`: M√©triques m√©moire (total, available, cached, etc.)
- `node_filesystem_*`: Utilisation disque par filesystem
- `node_disk_*`: I/O disque (read/write bytes, iops)
- `node_network_*`: Statistiques r√©seau (bytes, packets, errors)
- `node_load*`: Charge syst√®me (1m, 5m, 15m)

### Telegraf (port 9273)

- `cpu_usage_*`: M√©triques CPU d√©taill√©es
- `mem_*`: M√©triques m√©moire
- `disk_*`: M√©triques disque
- `diskio_*`: I/O disque
- `net_*`: Statistiques r√©seau
- `processes_*`: Statistiques processus
- `kernel_*`: M√©triques kernel

### Prometheus (port 9090)

- M√©triques internes Prometheus
- M√©triques des targets scraped
- √âtat des alertes

---

## üÜò Support

Pour toute question ou probl√®me:

1. Consulter la section [D√©pannage](#d√©pannage)
2. V√©rifier les logs: `docker-compose logs`
3. V√©rifier le statut: `docker-compose ps`
4. V√©rifier la sant√©: `make health`

---

## üìù Notes Importantes

- **Mots de passe par d√©faut**: √Ä changer en production
- **R√©seaux**: IPs fixes pour simulation cluster r√©el
- **Volumes**: Donn√©es Prometheus et Grafana persistantes
- **Compatibilit√©**: Docker 20.10+ requis (API 1.41)
- **Air-gapped**: Package exportable pour d√©ploiement offline

---

## üìÑ Licence

Projet interne - Usage d√©fense/a√©rospatial.

---

**Version**: 1.0  
**Derni√®re mise √† jour**: 2024  
**Maintenu par**: HPC Team
