# Guide Utilisateur - Cluster HPC
## Guide pour les Utilisateurs Finaux

**Classification**: Documentation Utilisateur  
**Public**: Utilisateurs du Cluster  
**Version**: 1.0  
**Date**: 2024

---

## üìã Table des Mati√®res

1. [Premiers Pas](#premiers-pas)
2. [Authentification](#authentification)
3. [Soumission de Jobs](#soumission-de-jobs)
4. [Gestion des Fichiers](#gestion-des-fichiers)
5. [Exemples de Jobs](#exemples-de-jobs)
6. [Bonnes Pratiques](#bonnes-pratiques)

---

## üöÄ Premiers Pas

### Connexion au Cluster

```bash
# Connexion SSH
ssh votre-utilisateur@frontal-01.cluster.local

# Ou directement sur un n≈ìud de calcul
ssh votre-utilisateur@node-01.cluster.local
```

### V√©rifier Votre Compte

```bash
# V√©rifier votre identit√©
whoami
id

# V√©rifier votre quota
quota -s
```

---

## üîê Authentification

### Avec LDAP + Kerberos

```bash
# Obtenir un ticket Kerberos
kinit votre-utilisateur@CLUSTER.LOCAL
# Entrer votre mot de passe

# V√©rifier le ticket
klist

# Le ticket permet l'authentification SSO (pas besoin de mot de passe pour SSH)
```

### Avec FreeIPA

```bash
# Obtenir un ticket Kerberos
kinit votre-utilisateur@CLUSTER.LOCAL
# Entrer votre mot de passe

# V√©rifier le ticket
klist
```

---

## ‚ö° Soumission de Jobs

### Job Simple

**Fichier** : `mon-job.sh`
```bash
#!/bin/bash
#SBATCH --job-name=mon-job
#SBATCH --output=mon-job-%j.out
#SBATCH --error=mon-job-%j.err
#SBATCH --time=1:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1

echo "Bonjour depuis le cluster HPC!"
hostname
date
```

**Soumission** :
```bash
sbatch mon-job.sh
```

**V√©rification** :
```bash
squeue -u $USER
```

### Job avec Plusieurs C≈ìurs

```bash
#!/bin/bash
#SBATCH --job-name=job-parallele
#SBATCH --output=job-parallele-%j.out
#SBATCH --time=2:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=1

# Job utilisant 4 c≈ìurs
./mon-programme-parallele
```

### Job MPI

```bash
#!/bin/bash
#SBATCH --job-name=job-mpi
#SBATCH --output=job-mpi-%j.out
#SBATCH --time=4:00:00
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=4

# Job MPI sur 2 n≈ìuds, 4 processus par n≈ìud
srun ./mon-programme-mpi
```

---

## üìÅ Gestion des Fichiers

### Espace de Travail

```bash
# Votre r√©pertoire home
cd ~
pwd  # /home/votre-utilisateur

# Espace de travail partag√© (GPFS)
cd /gpfs/home/votre-utilisateur
```

### Transfert de Fichiers

**Depuis votre machine locale** :
```bash
# SCP
scp fichier.txt votre-utilisateur@frontal-01:/home/votre-utilisateur/

# SFTP
sftp votre-utilisateur@frontal-01
put fichier.txt
```

### Quotas

```bash
# V√©rifier votre quota
quota -s

# V√©rifier l'utilisation
du -sh ~
du -sh /gpfs/home/votre-utilisateur
```

---

## üí° Exemples de Jobs

### Job Python

```bash
#!/bin/bash
#SBATCH --job-name=python-job
#SBATCH --output=python-%j.out
#SBATCH --time=1:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1

# Charger l'environnement Python
module load python/3.9

# Ex√©cuter le script
python mon-script.py
```

### Job MATLAB

```bash
#!/bin/bash
#SBATCH --job-name=matlab-job
#SBATCH --output=matlab-%j.out
#SBATCH --time=2:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1

# Charger MATLAB
module load matlab

# Ex√©cuter le script MATLAB
matlab -batch "run('mon-script.m')"
```

### Job avec Array

```bash
#!/bin/bash
#SBATCH --job-name=array-job
#SBATCH --output=array-%A-%a.out
#SBATCH --array=1-10
#SBATCH --time=1:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1

# Job array : 10 jobs identiques avec param√®tres diff√©rents
echo "Job $SLURM_ARRAY_JOB_ID, Task $SLURM_ARRAY_TASK_ID"
./mon-programme --param $SLURM_ARRAY_TASK_ID
```

---

## ‚úÖ Bonnes Pratiques

### Avant de Soumettre un Job

1. **Tester localement** : V√©rifier que votre code fonctionne
2. **Estimer le temps** : Utiliser `--time` appropri√©
3. **V√©rifier les ressources** : CPU, m√©moire, GPU si n√©cessaire
4. **V√©rifier les fichiers** : S'assurer que tous les fichiers sont accessibles

### Pendant l'Ex√©cution

1. **Surveiller** : Utiliser `squeue` pour v√©rifier l'√©tat
2. **Consulter les logs** : V√©rifier les fichiers `.out` et `.err`
3. **Ne pas surcharger** : Ne pas soumettre trop de jobs simultan√©ment

### Apr√®s l'Ex√©cution

1. **V√©rifier les r√©sultats** : S'assurer que le job a r√©ussi
2. **Nettoyer** : Supprimer les fichiers temporaires
3. **Archiver** : Sauvegarder les r√©sultats importants

---

## üîß Commandes Utiles

### Slurm

```bash
# Soumettre un job
sbatch mon-job.sh

# V√©rifier l'√©tat
squeue -u $USER

# Annuler un job
scancel <job-id>

# D√©tails d'un job
scontrol show job <job-id>

# Historique
sacct -u $USER
```

### Fichiers

```bash
# Taille des fichiers
du -sh *

# Rechercher des fichiers
find . -name "*.out"

# Compresser
tar -czf archive.tar.gz dossier/
```

---

## üìö Ressources

- **Guide Lancement Jobs** : `docs/GUIDE_LANCEMENT_JOBS.md`
- **Guide Authentification** : `docs/GUIDE_AUTHENTIFICATION.md`
- **Support** : contact-admin@cluster.local

---

**Version**: 1.0  
**Derni√®re mise √† jour**: 2024
