# Configuration Slurm pour Cluster HPC
# Architecture: 2 frontaux + 6 compute nodes

ClusterName=hpc-demo
ControlMachine=frontal-01
ControlAddr=172.20.0.101
SlurmUser=slurm
SlurmctldPort=6817
SlurmdPort=6818
AuthType=auth/munge
StateSaveLocation=/var/spool/slurm/ctld
SlurmdSpoolDir=/var/spool/slurm/d
SwitchType=switch/none
MpiDefault=none
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
ProctrackType=proctrack/cgroup
ReturnToService=0
SlurmctldParameters=enable_configless
SlurmdParameters=enable_configless

# ============================================
# PARTITIONS
# ============================================

PartitionName=normal Nodes=slave-[01-06] Default=YES MaxTime=INFINITE State=UP
PartitionName=gpu Nodes=slave-[01-02] MaxTime=INFINITE State=UP

# ============================================
# NODES
# ============================================

NodeName=frontal-01 NodeAddr=172.20.0.101 CPUs=4 RealMemory=8192 State=UNKNOWN
NodeName=frontal-02 NodeAddr=172.20.0.102 CPUs=4 RealMemory=8192 State=UNKNOWN
NodeName=slave-01 NodeAddr=172.20.0.201 CPUs=8 RealMemory=16384 State=UNKNOWN
NodeName=slave-02 NodeAddr=172.20.0.202 CPUs=8 RealMemory=16384 State=UNKNOWN
NodeName=slave-03 NodeAddr=172.20.0.203 CPUs=8 RealMemory=16384 State=UNKNOWN
NodeName=slave-04 NodeAddr=172.20.0.204 CPUs=8 RealMemory=16384 State=UNKNOWN
NodeName=slave-05 NodeAddr=172.20.0.205 CPUs=8 RealMemory=16384 State=UNKNOWN
NodeName=slave-06 NodeAddr=172.20.0.206 CPUs=8 RealMemory=16384 State=UNKNOWN
